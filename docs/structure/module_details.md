# æ ¸å¿ƒæ¨¡å—è¯¦ç»†è¯´æ˜

> æœ€åæ›´æ–°ï¼š2025-12-31

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å„æ ¸å¿ƒæ¨¡å—çš„å®ç°ç»†èŠ‚ã€æ¥å£å®šä¹‰å’Œä½¿ç”¨æ–¹å¼ã€‚

---

## ğŸ“‹ ç›®å½•

- [1. LLM å®¢æˆ·ç«¯ (LLMClient)](#1-llm-å®¢æˆ·ç«¯-llmclient)
- [2. æµç¨‹ç¼–æ’å™¨ (ProcessManager)](#2-æµç¨‹ç¼–æ’å™¨-processmanager)
- [3. å¤„ç†å™¨å±‚ (Processors)](#3-å¤„ç†å™¨å±‚-processors)
- [4. è¾“å‡ºå±‚ (OutputHandlers)](#4-è¾“å‡ºå±‚-outputhandlers)
- [5. é£ä¹¦å®¢æˆ·ç«¯ (FeishuClient)](#5-é£ä¹¦å®¢æˆ·ç«¯-feishuclient)
- [6. å·¥å…·å±‚ (Utils)](#6-å·¥å…·å±‚-utils)
- [7. ä»»åŠ¡å­˜å‚¨ (TaskStore)](#7-ä»»åŠ¡å­˜å‚¨-taskstore)

---

## 1. LLM å®¢æˆ·ç«¯ (LLMClient)

**æ–‡ä»¶ä½ç½®**ï¼š`backend/core/llm_client.py`

### 1.1 æ ¸å¿ƒèŒè´£

- ä¸ LLM API è¿›è¡Œé€šä¿¡
- å®ç°å¤š Provider Fallback æœºåˆ¶
- ç®¡ç†è¶…æ—¶å’Œé‡è¯•
- ç»Ÿä¸€é”™è¯¯å¤„ç†

### 1.2 å…³é”®ç±»å’Œæ¥å£

#### LLMClient

```python
class LLMClient:
    async def chat_completion(
        self,
        *,
        chain: str,              # Chain åç§°ï¼ˆå¦‚ "idea_expand"ï¼‰
        messages: List[Dict],    # æ¶ˆæ¯åˆ—è¡¨
        **options: Any           # é¢å¤–é€‰é¡¹ï¼ˆtemperature ç­‰ï¼‰
    ) -> str:
        """
        ç»Ÿä¸€çš„ LLM è°ƒç”¨æ¥å£
        
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
            
        Raises:
            FallbackExhaustedError: æ‰€æœ‰ Provider éƒ½å¤±è´¥
            NonRetryableLLMError: ä¸å¯é‡è¯•çš„é”™è¯¯
        """
```

### 1.3 é…ç½®ç»“æ„

**æ–‡ä»¶**ï¼š`llm_config.yml`

```yaml
providers:
  provider_name:
    type: "openai-compatible"  # Provider ç±»å‹
    base_url: "https://..."    # API åŸºç¡€ URL
    model: "model-name"        # æ¨¡å‹åç§°
    api_key_env: "ENV_VAR"     # ç¯å¢ƒå˜é‡å

chains:
  chain_name:
    - provider: "provider_name"  # Provider åç§°
      timeout_s: 60              # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

global:
  max_retries_per_provider: 1   # æ¯ä¸ª Provider æœ€å¤§é‡è¯•æ¬¡æ•°
  overall_timeout_s: 60         # å…¨å±€è¶…æ—¶
```

### 1.4 Fallback æœºåˆ¶

**æµç¨‹**ï¼š
```
1. é€‰æ‹© Chainï¼ˆå¦‚ "idea_expand"ï¼‰
2. éå† Chain ä¸­çš„ Provider åˆ—è¡¨
3. å¯¹æ¯ä¸ª Providerï¼š
   a. å°è¯•è°ƒç”¨
   b. æˆåŠŸ â†’ è¿”å›ç»“æœ
   c. å¯é‡è¯•é”™è¯¯ â†’ ç»§ç»­ä¸‹ä¸€ä¸ª
   d. ä¸å¯é‡è¯•é”™è¯¯ â†’ ç›´æ¥æŠ›å‡º
4. æ‰€æœ‰ Provider å¤±è´¥ â†’ æŠ›å‡º FallbackExhaustedError
```

**é”™è¯¯åˆ†ç±»**ï¼š
- **å¯é‡è¯•**ï¼šç½‘ç»œé”™è¯¯ã€è¶…æ—¶ã€5xx é”™è¯¯
- **ä¸å¯é‡è¯•**ï¼šå‚æ•°é”™è¯¯ã€è®¤è¯å¤±è´¥ã€é…é¢è€—å°½

### 1.5 ä½¿ç”¨ç¤ºä¾‹

```python
llm_client = LLMClient()

# è°ƒç”¨ LLM
response = await llm_client.chat_completion(
    chain="idea_expand",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ª..."},
        {"role": "user", "content": "è¯·..."}
    ],
    temperature=0.7
)
```

---

## 2. æµç¨‹ç¼–æ’å™¨ (ProcessManager)

**æ–‡ä»¶ä½ç½®**ï¼š`backend/core/manager.py`

### 2.1 æ ¸å¿ƒèŒè´£

- ç¼–æ’æ•´ä¸ªå¤„ç†æµç¨‹
- é€‰æ‹©åˆé€‚çš„ Processor å’Œ OutputHandler
- ç®¡ç†è¿›åº¦æŠ¥å‘Š
- å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•

### 2.2 å…³é”®ç±»å’Œæ¥å£

#### ProcessContext

```python
@dataclass
class ProcessContext:
    doc_token: str                  # æ–‡æ¡£ token
    user_id: str                    # ç”¨æˆ· ID
    mode: str                       # å¤„ç†æ¨¡å¼
    trigger_source: str | None      # è§¦å‘æ¥æº
    wiki_node_token: str | None     # Wiki èŠ‚ç‚¹ token
    wiki_space_id: str | None       # Wiki ç©ºé—´ ID
```

#### ProcessResult

```python
@dataclass
class ProcessResult:
    child_doc_token: Optional[str]       # å­æ–‡æ¡£ token
    child_doc_url: Optional[str]         # å­æ–‡æ¡£ URL
    processor_result: ProcessorResult    # å¤„ç†å™¨ç»“æœ
    output_result: OutputResult          # è¾“å‡ºç»“æœ
```

#### ProcessManager

```python
class ProcessManager:
    async def process_doc(
        self, 
        ctx: ProcessContext,
        *, 
        progress: ProgressFn | None = None
    ) -> ProcessResult:
        """
        ä¸»å¤„ç†æµç¨‹
        
        Args:
            ctx: å¤„ç†ä¸Šä¸‹æ–‡
            progress: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            å¤„ç†ç»“æœ
        """
```

### 2.3 å¤„ç†æµç¨‹

```python
# è¯¦ç»†æµç¨‹
async def process_doc(ctx: ProcessContext):
    # 1. è·å– Workflow é…ç½®
    workflow = registry.get(ctx.mode)
    
    # 2. è·å–æ–‡æ¡£å…ƒä¿¡æ¯
    await progress("fetch_meta", 5, "è·å–æ–‡æ¡£å…ƒä¿¡æ¯")
    file_meta = await feishu.get_doc_meta(ctx.doc_token)
    
    # 3. è¯»å–æ–‡æ¡£å†…å®¹
    await progress("fetch_content", 15, "è¯»å–æ–‡æ¡£å†…å®¹")
    doc_content = await feishu.get_doc_content(ctx.doc_token)
    
    # 4. æ‰§è¡Œ Processor
    await progress("llm", 35, "è°ƒç”¨æ¨¡å‹ç”Ÿæˆå†…å®¹")
    processor = workflow.processor_cls(llm_client)
    processor_result = await processor.run(
        doc_content=doc_content,
        doc_title=doc_title,
        chain=workflow.chain
    )
    
    # 5. è¾“å‡ºå¤„ç†
    await progress("output", 80, "è¾“å‡ºè½åœ°ï¼ˆå†™å…¥/æ¨é€ï¼‰")
    output_handler = workflow.output_factory(feishu, llm_client)
    output_result = await output_handler.handle(
        ctx=ctx,
        source_doc=SourceDoc(...),
        processor_result=processor_result
    )
    
    # 6. è¿”å›ç»“æœ
    await progress("done", 100, "å¤„ç†å®Œæˆ")
    return ProcessResult(...)
```

### 2.4 è¿›åº¦æŠ¥å‘Š

**è¿›åº¦å›è°ƒç­¾å**ï¼š
```python
ProgressFn = Callable[[str, int, str], Awaitable[None]]
# å‚æ•°ï¼š(stage, percent, message)
```

**æ ‡å‡†è¿›åº¦é˜¶æ®µ**ï¼š
- `fetch_meta` (5%): è·å–æ–‡æ¡£å…ƒä¿¡æ¯
- `fetch_content` (15%): è¯»å–æ–‡æ¡£å†…å®¹
- `llm` (35%): è°ƒç”¨æ¨¡å‹ç”Ÿæˆå†…å®¹
- `output` (80%): è¾“å‡ºè½åœ°
- `done` (100%): å¤„ç†å®Œæˆ

---

## 3. å¤„ç†å™¨å±‚ (Processors)

**ç›®å½•ä½ç½®**ï¼š`backend/services/processors/`

### 3.1 æ ¸å¿ƒèŒè´£

- æ ¹æ®ä¸åŒæ¨¡å¼å¤„ç†æ–‡æ¡£å†…å®¹
- ç»„è£… LLM Prompt
- è°ƒç”¨ LLM ç”Ÿæˆç»“æœ
- è¿”å›æ ‡å‡†åŒ–ç»“æœ

### 3.2 æŠ½è±¡åŸºç±»

#### BaseDocProcessor

```python
class BaseDocProcessor(ABC):
    def __init__(self, llm_client: LLMClientLike) -> None:
        self.llm_client = llm_client
    
    @abstractmethod
    async def run(
        self,
        *,
        doc_content: str,           # æ–‡æ¡£å†…å®¹
        doc_title: str,             # æ–‡æ¡£æ ‡é¢˜
        chain: str,                 # LLM Chain åç§°
        context: Dict[str, Any] | None = None  # ä¸Šä¸‹æ–‡ä¿¡æ¯
    ) -> ProcessorResult:
        """å¤„ç†æ–‡æ¡£å†…å®¹ï¼Œè¿”å›æ ‡å‡†åŒ–ç»“æœ"""
```

#### ProcessorResult

```python
@dataclass
class ProcessorResult:
    title: str                          # ç”Ÿæˆçš„æ ‡é¢˜
    content_md: str                     # ç”Ÿæˆçš„å†…å®¹ï¼ˆMarkdownï¼‰
    summary: Optional[str] = None       # æ‘˜è¦
    metadata: Optional[Dict] = None     # å…ƒæ•°æ®
```

### 3.3 å…·ä½“å®ç°

#### 3.3.1 IdeaExpanderProcessorï¼ˆæ€è·¯æ‰©å±•ï¼‰

**æ–‡ä»¶**ï¼š`processors/expander.py`

**ç‰¹ç‚¹**ï¼š
- ä¾§é‡å‘æ•£æ€§æ€ç»´
- ç”Ÿæˆ 3-5 ä¸ªå»¶ä¼¸æ–¹å‘
- Prompt å¼ºè°ƒ"å¤´è„‘é£æš´"ã€"åˆ—å‡ºå¯èƒ½æ€§"

**Prompt ç»“æ„**ï¼š
```python
system_prompt = """
ä½ æ˜¯ä¸€ä¸ªäº§å“åˆ›æ„é¡¾é—®ï¼Œæ“…é•¿åŸºäºå·²æœ‰æ–‡æ¡£æå‡ºå¤šæ ·åŒ–çš„å»¶ä¼¸ç‚¹å­ã€‚
- è¾“å‡ºä½¿ç”¨ Markdownï¼ŒæŒ‰"æ‘˜è¦ / å»¶ä¼¸æ–¹å‘ / ä¸‹ä¸€æ­¥è¡ŒåŠ¨"ç»“æ„ç»„ç»‡ã€‚
- ç»™å‡ºæœ‰åŒºåˆ†åº¦çš„è¦ç‚¹ï¼Œæ¯æ¡ç”¨åºå·æˆ–å°æ ‡é¢˜ã€‚
- ä¿æŒå®¢è§‚ã€å…·ä½“ï¼Œå¯æ‰§è¡Œã€‚
"""

user_prompt = f"""
å½“å‰æ–‡æ¡£æ ‡é¢˜ï¼š{doc_title}
æ–‡æ¡£æ­£æ–‡ï¼š
{doc_content}

è¯·åŸºäºå†…å®¹ç”Ÿæˆ 3-5 ä¸ªå»¶ä¼¸æ–¹å‘å¹¶è¡¥å……å¯¹åº”çš„å®æ–½å»ºè®®ã€‚
"""
```

**è°ƒç”¨å‚æ•°**ï¼š
- Chain: `idea_expand`
- Temperature: 0.7ï¼ˆå…è®¸åˆ›é€ æ€§ï¼‰

---

#### 3.3.2 ResearchProcessorï¼ˆæ·±åº¦è°ƒç ”ï¼‰

**æ–‡ä»¶**ï¼š`processors/researcher.py`

**ç‰¹ç‚¹**ï¼š
- ä¸¤é˜¶æ®µå¤„ç†ï¼ˆRefine â†’ Deep Researchï¼‰
- ä¾§é‡æ·±åº¦å’Œç»“æ„åŒ–
- æ”¯æŒé•¿æ—¶ä»»åŠ¡

**é˜¶æ®µ 1: Refineï¼ˆä¼˜åŒ–æŒ‡ä»¤ï¼‰**

```python
# Prompt
system_prompt = """
ä½ æ˜¯æç¤ºè¯ä¼˜åŒ–å™¨ï¼Œè´Ÿè´£æŠŠç”¨æˆ·çš„éœ€æ±‚è½¬æˆå¯æ‰§è¡Œçš„"æ·±åº¦è°ƒç ”æŒ‡ä»¤"ã€‚
è¦æ±‚ï¼š
- è¾“å‡ºç®€æ´è¦ç‚¹åˆ—è¡¨ï¼Œè¦†ç›–ï¼šè°ƒç ”ä¸»é¢˜ã€æ ¸å¿ƒé—®é¢˜ã€éœ€éªŒè¯çš„å‡è®¾ã€å…³é”®ä¿¡æ¯æºã€‚
- ä¿æŒä¸­ç«‹ï¼Œé¿å…è‡†æµ‹ï¼Œå¿…è¦æ—¶æ˜ç¡®"ä¸è¶³/å¾…ç¡®è®¤"ã€‚
"""

user_prompt = f"""
åŸæ–‡æ ‡é¢˜ï¼š{doc_title}
åŸæ–‡å†…å®¹ï¼š
{doc_content}

è¯·ç”Ÿæˆä¸€ä»½"æ·±åº¦è°ƒç ”æŒ‡ä»¤"ï¼Œä¾¿äºåç»­æ¨¡å‹æ®æ­¤å®Œæˆè°ƒç ”ã€‚
"""

# è°ƒç”¨å‚æ•°
chain: "research_refine"
temperature: 0.3ï¼ˆæ›´ç²¾ç¡®ï¼‰
```

**é˜¶æ®µ 2: Deep Researchï¼ˆæ·±åº¦è°ƒç ”ï¼‰**

```python
# Prompt
system_prompt = """
ä½ æ˜¯æ·±åº¦ç ”ç©¶åŠ©æ‰‹ï¼Œè¯·åŸºäºç»™å®šçš„"è°ƒç ”æŒ‡ä»¤"ç”Ÿæˆå®Œæ•´çš„è°ƒç ”æŠ¥å‘Šï¼ˆMarkdownï¼‰ã€‚
è¾“å‡ºç»“æ„å»ºè®®ï¼š
- èƒŒæ™¯ä¸èŒƒå›´
- æ ¸å¿ƒå‘ç°ï¼ˆåˆ†ç‚¹æè¿°ï¼Œå¯å«å¼•ç”¨æˆ–å‡ºå¤„è¯´æ˜ï¼‰
- è®ºè¯ä¸è¯æ®ï¼ˆè¯´æ˜ä¾æ®ï¼Œæ ‡æ³¨å¯èƒ½çš„ä¸ç¡®å®šæ€§ï¼‰
- é£é™©ä¸å¾…éªŒè¯é—®é¢˜
- å»ºè®®è¡ŒåŠ¨ï¼ˆå…·ä½“ã€å¯æ‰§è¡Œï¼‰
å¦‚ä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®å“ªäº›éƒ¨åˆ†ç¼ºä¹æ”¯æ’‘ï¼Œä¸è¦ç¼–é€ ã€‚
"""

user_prompt = f"""
è°ƒç ”æŒ‡ä»¤ï¼š
{refined_prompt}

è¯·ç›´æ¥è¾“å‡º Markdown è°ƒç ”æŠ¥å‘Šã€‚
"""

# è°ƒç”¨å‚æ•°
chain: "research_deep"
temperature: 0.2ï¼ˆæ›´ä¸¥è°¨ï¼‰
timeout: 2500sï¼ˆé•¿æ—¶ä»»åŠ¡ï¼‰
```

**è¿›åº¦æŠ¥å‘Š**ï¼š
```python
await progress("llm_refine", 45, "ä¼˜åŒ–è°ƒç ”æŒ‡ä»¤")
# ... refine é˜¶æ®µ ...
await progress("llm_research", 70, "æ·±åº¦è°ƒç ”ä¸­ï¼Œå¯èƒ½è€—æ—¶è¾ƒé•¿")
# ... deep research é˜¶æ®µ ...
await progress("llm_done", 90, "è°ƒç ”ç»“æœå·²ç”Ÿæˆ")
```

### 3.4 æ‰©å±•æ–° Processor

**æ­¥éª¤**ï¼š

1. **åˆ›å»ºæ–°ç±»**ï¼š
```python
# backend/services/processors/my_processor.py
from backend.services.processors.base import BaseDocProcessor, ProcessorResult

class MyProcessor(BaseDocProcessor):
    async def run(self, *, doc_content, doc_title, chain, context=None):
        # 1. ç»„è£… Prompt
        system_prompt = "..."
        user_prompt = f"..."
        
        # 2. è°ƒç”¨ LLM
        result = await self.llm_client.chat_completion(
            chain=chain,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7
        )
        
        # 3. è¿”å›ç»“æœ
        return ProcessorResult(
            title=f"{doc_title} - æˆ‘çš„å¤„ç†",
            content_md=result,
            summary="å¤„ç†å®Œæˆ",
            metadata={"mode": "my_mode"}
        )
```

2. **æ³¨å†Œåˆ° Registry**ï¼š
```python
# backend/services/processors/registry.py
from backend.services.processors.my_processor import MyProcessor

PROCESSOR_REGISTRY = {
    "idea_expander": IdeaExpanderProcessor,
    "research": ResearchProcessor,
    "my_processor": MyProcessor,  # æ–°å¢
}
```

3. **é…ç½® Workflow**ï¼š
```yaml
# workflow_config.yml
workflows:
  my_mode:
    processor: "my_processor"
    chain: "my_chain"
    output: "feishu_child_doc"
    notify_user: true
```

4. **é…ç½® LLM Chain**ï¼š
```yaml
# llm_config.yml
chains:
  my_chain:
    - provider: "primary_gemini"
      timeout_s: 60
```

---

## 4. è¾“å‡ºå±‚ (OutputHandlers)

**ç›®å½•ä½ç½®**ï¼š`backend/services/outputs/`

### 4.1 æ ¸å¿ƒèŒè´£

- å°†å¤„ç†ç»“æœè¾“å‡ºåˆ°ä¸åŒç›®æ ‡
- åˆ›å»ºå­æ–‡æ¡£ï¼ˆé£ä¹¦ï¼‰
- æ¨é€é€šçŸ¥ï¼ˆWebhookã€å¡ç‰‡æ¶ˆæ¯ï¼‰
- å›é“¾åŸæ–‡æ¡£

### 4.2 æŠ½è±¡åŸºç±»

#### BaseOutputHandler

```python
class BaseOutputHandler(ABC):
    @abstractmethod
    async def handle(
        self,
        *,
        ctx: ProcessContext,                # å¤„ç†ä¸Šä¸‹æ–‡
        source_doc: SourceDoc,              # åŸæ–‡æ¡£ä¿¡æ¯
        processor_result: ProcessorResult,  # å¤„ç†å™¨ç»“æœ
        notify_user: bool = True            # æ˜¯å¦é€šçŸ¥ç”¨æˆ·
    ) -> OutputResult:
        """å¤„ç†è¾“å‡º"""
```

#### SourceDoc

```python
@dataclass
class SourceDoc:
    doc_token: str              # æ–‡æ¡£ token
    title: str                  # æ–‡æ¡£æ ‡é¢˜
    parent_token: Optional[str] # çˆ¶ç›®å½• token
```

#### OutputResult

```python
@dataclass
class OutputResult:
    child_doc_token: Optional[str]   # å­æ–‡æ¡£ token
    child_doc_url: Optional[str]     # å­æ–‡æ¡£ URL
    metadata: Optional[Dict] = None  # å…ƒæ•°æ®
```

### 4.3 å…·ä½“å®ç°

#### 4.3.1 FeishuChildDocOutputHandler

**æ–‡ä»¶**ï¼š`outputs/feishu_child_doc.py`

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

**1. æ™ºèƒ½æ ‡é¢˜ç”Ÿæˆ** ğŸ†•
```python
# æ£€æµ‹"æœªå‘½å"æ–‡æ¡£
title = processor_result.title
if "æœªå‘½å" in title:
    # è°ƒç”¨ TitleGenerator
    title = await self._title_generator.generate_title(
        content_md=processor_result.content_md,
        mode=ctx.mode,
        original_doc_title=source_doc.title
    )
```

**2. åˆ›å»ºå­æ–‡æ¡£ï¼ˆæ”¯æŒ Wikiï¼‰**
```python
if wiki_node_token:
    # === Wiki çŸ¥è¯†åº“è·¯å¾„ ===
    child_node = await feishu.create_wiki_child_doc(
        space_id=wiki_space_id,
        parent_node_token=wiki_node_token,
        title=title
    )
    child_doc_token = child_node["obj_token"]
else:
    # === äº‘ç›˜è·¯å¾„ ===
    child_doc_token = await feishu.create_child_doc(
        folder_token=parent_token,
        title=title
    )
```

**3. å†™å…¥å†…å®¹**
```python
await feishu.write_doc_content(
    child_doc_token,
    processor_result.content_md
)
```

**4. å›é“¾åŸæ–‡æ¡£**
```python
await feishu.append_reference_block(
    source_doc.doc_token,
    title,
    child_doc_url
)
```

**5. å‘é€é€šçŸ¥å¡ç‰‡**
```python
if notify_user:
    card = self._build_notify_card(...)
    await feishu.send_card(
        user_id=ctx.user_id,
        card_content=card
    )
```

---

#### 4.3.2 WebhookOutputHandler

**æ–‡ä»¶**ï¼š`outputs/webhook.py`

**åŠŸèƒ½**ï¼šå°†ç»“æœæ¨é€åˆ°å¤–éƒ¨ Webhook

**Payload ç»“æ„**ï¼š
```json
{
  "mode": "idea_expand",
  "doc_token": "doccn...",
  "user_id": "ou_...",
  "title": "ç”Ÿæˆçš„æ ‡é¢˜",
  "content_md": "# å†…å®¹...",
  "summary": "æ‘˜è¦",
  "metadata": {...}
}
```

**é…ç½®**ï¼š
```env
WEBHOOK_OUTPUT_URL=https://example.com/webhook
WEBHOOK_OUTPUT_TIMEOUT_S=10.0
```

### 4.4 æ‰©å±•æ–° OutputHandler

**æ­¥éª¤**ï¼š

1. **åˆ›å»ºæ–°ç±»**ï¼š
```python
# backend/services/outputs/my_output.py
from backend.services.outputs.base import BaseOutputHandler, OutputResult

class MyOutputHandler(BaseOutputHandler):
    async def handle(self, *, ctx, source_doc, processor_result, notify_user):
        # 1. å¤„ç†è¾“å‡ºé€»è¾‘
        # ä¾‹å¦‚ï¼šå‘é€é‚®ä»¶ã€å†™å…¥æ•°æ®åº“ç­‰
        
        # 2. è¿”å›ç»“æœ
        return OutputResult(
            child_doc_token=None,  # å¦‚æœä¸åˆ›å»ºæ–‡æ¡£
            child_doc_url=None,
            metadata={"output": "my_output"}
        )
```

2. **æ³¨å†Œåˆ° Registry**ï¼š
```python
# backend/services/outputs/registry.py
def _make_my_output(feishu: FeishuClient, llm: LLMClient):
    return MyOutputHandler(...)

OUTPUT_REGISTRY = {
    "feishu_child_doc": _make_feishu_child_doc_output,
    "webhook": _make_webhook_output,
    "my_output": _make_my_output,  # æ–°å¢
}
```

3. **é…ç½® Workflow**ï¼š
```yaml
# workflow_config.yml
workflows:
  my_mode:
    processor: "idea_expander"
    chain: "idea_expand"
    output: "my_output"  # ä½¿ç”¨æ–°çš„è¾“å‡º
    notify_user: false
```

---

## 5. é£ä¹¦å®¢æˆ·ç«¯ (FeishuClient)

**æ–‡ä»¶ä½ç½®**ï¼š`backend/services/feishu.py`

### 5.1 æ ¸å¿ƒèŒè´£

- Token ç®¡ç†ï¼ˆè·å–ã€ç¼“å­˜ã€åˆ·æ–°ï¼‰
- æ–‡æ¡£æ“ä½œï¼ˆè¯»ã€å†™ã€åˆ›å»ºï¼‰
- Wiki çŸ¥è¯†åº“æ“ä½œ
- æ¶ˆæ¯å‘é€

### 5.2 å…³é”®æ¥å£

#### Token ç®¡ç†

```python
async def get_tenant_access_token() -> str:
    """è·å–å¹¶ç¼“å­˜ tenant_access_token"""
```

**å®ç°ç»†èŠ‚**ï¼š
- å†…å­˜ç¼“å­˜
- TTL æ§åˆ¶ï¼ˆæå‰ 60 ç§’åˆ·æ–°ï¼‰
- çº¿ç¨‹å®‰å…¨ï¼ˆasyncio.Lockï¼‰

#### æ–‡æ¡£æ“ä½œ

```python
# è·å–æ–‡æ¡£å…ƒä¿¡æ¯
async def get_doc_meta(doc_token: str) -> Dict[str, Any]:
    """è¿”å›: title, parent_token ç­‰"""

# è·å–æ–‡æ¡£å†…å®¹
async def get_doc_content(doc_token: str) -> str:
    """è¿”å›çº¯æ–‡æœ¬å†…å®¹"""

# åˆ›å»ºå­æ–‡æ¡£
async def create_child_doc(folder_token: str, title: str) -> str:
    """è¿”å›: child_doc_token"""

# å†™å…¥æ–‡æ¡£å†…å®¹
async def write_doc_content(doc_token: str, content_md: str) -> None:
    """Markdown â†’ Blocks â†’ å†™å…¥"""

# æ·»åŠ å¼•ç”¨å—
async def append_reference_block(
    doc_token: str, 
    child_title: str, 
    child_url: str
) -> None:
    """åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ é“¾æ¥"""
```

#### Wiki æ“ä½œ

```python
# è·å– Wiki èŠ‚ç‚¹ä¿¡æ¯
async def get_wiki_node_by_token(node_token: str) -> Dict[str, Any]:
    """è¿”å›: space_id, obj_token ç­‰"""

# åˆ›å»º Wiki å­èŠ‚ç‚¹
async def create_wiki_child_doc(
    space_id: str,
    parent_node_token: str,
    title: str,
    obj_type: str = "docx"
) -> Dict[str, Any]:
    """è¿”å›: node_token, obj_token ç­‰"""
```

#### æ¶ˆæ¯å‘é€

```python
async def send_card(
    user_id: str,
    card_content: Dict[str, Any],
    receive_id_type: str = "open_id"
) -> None:
    """å‘é€é£ä¹¦å¡ç‰‡æ¶ˆæ¯"""
```

### 5.3 å®¹é”™æœºåˆ¶

#### Markdown å†™å…¥å¤šçº§å›é€€

```python
async def write_doc_content(doc_token, content_md):
    # 1. é•¿åº¦æˆªæ–­
    if len(content_md) > 60000:
        content_md = content_md[:60000] + "\n\nï¼ˆå†…å®¹å·²æˆªæ–­ï¼‰"
    
    # 2. ä¼˜å…ˆï¼šMarkdown â†’ Blocks
    try:
        blocks = await convert_markdown_to_blocks(content_md)
        if len(blocks) <= 1000:
            await add_blocks_descendant(doc_token, blocks)
            return
    except FeishuAPIError:
        pass  # é™çº§
    
    # 3. å›é€€ï¼šå•ä¸ª markdown block
    markdown_block = {
        "block_type": "markdown",
        "markdown": {"content": content_md}
    }
    await add_blocks_descendant(doc_token, [markdown_block])
```

#### é‡è¯•æœºåˆ¶

```python
async def _request_with_retry(method, path, max_retries=3):
    for attempt in range(max_retries):
        try:
            return await self._request(method, path)
        except FeishuAPIError as exc:
            if exc.status_code == 404 and attempt < max_retries - 1:
                await asyncio.sleep(5.0)
                continue
            raise
```

---

## 6. å·¥å…·å±‚ (Utils)

**ç›®å½•ä½ç½®**ï¼š`backend/services/utils/`

### 6.1 TitleGeneratorï¼ˆæ™ºèƒ½æ ‡é¢˜ç”Ÿæˆå™¨ï¼‰

**æ–‡ä»¶**ï¼š`utils/title_generator.py`

#### æ ¸å¿ƒåŠŸèƒ½

- åŸºäºæ–‡æ¡£å†…å®¹ç”Ÿæˆè¯­ä¹‰åŒ–æ ‡é¢˜
- ä½¿ç”¨å¿«é€Ÿ LLM æ¨¡å‹ï¼ˆ15ç§’å†…å®Œæˆï¼‰
- è‡ªåŠ¨æ¸…ç†æ ‡é¢˜æ ¼å¼
- å¤±è´¥æ—¶æä¾› fallback

#### æ¥å£å®šä¹‰

```python
class TitleGenerator:
    def __init__(
        self,
        *,
        llm_client: LLMClient,
        chain: str = "title_generation",
        content_preview_length: int = 800,
        max_title_length: int = 30
    ):
        """åˆå§‹åŒ–"""
    
    async def generate_title(
        self,
        *,
        content_md: str,                    # æ–‡æ¡£å†…å®¹
        mode: str,                          # å¤„ç†æ¨¡å¼
        original_doc_title: str | None      # åŸæ ‡é¢˜ï¼ˆå‚è€ƒï¼‰
    ) -> str:
        """
        ç”Ÿæˆæ ‡é¢˜
        
        Returns:
            ç”Ÿæˆçš„æ ‡é¢˜ï¼ˆå¤±è´¥æ—¶è¿”å› fallbackï¼‰
        """
```

#### å·¥ä½œæµç¨‹

```python
# 1. æå–å†…å®¹é¢„è§ˆ
content_preview = content_md[:800]

# 2. æ„é€  Prompt
system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ ‡é¢˜ç”ŸæˆåŠ©æ‰‹ã€‚
è¦æ±‚ï¼š
- æ ‡é¢˜é•¿åº¦ä¸è¶…è¿‡ 30 ä¸ªå­—ç¬¦
- ç›´æ¥ä½“ç°æ–‡æ¡£çš„æ ¸å¿ƒä¸»é¢˜æˆ–ä»·å€¼
- é¿å…ä½¿ç”¨"æœªå‘½å"ã€"æ–‡æ¡£"ç­‰é€šç”¨è¯æ±‡
"""

user_prompt = f"""
è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ ‡é¢˜ï¼š
---
{content_preview}
---
"""

# 3. è°ƒç”¨ LLM
generated_title = await llm_client.chat_completion(
    chain="title_generation",
    messages=[...],
    temperature=0.7
)

# 4. æ¸…ç†æ ‡é¢˜
title = clean_title(generated_title)
# - ç§»é™¤å¼•å·
# - åªä¿ç•™ç¬¬ä¸€è¡Œ
# - é™åˆ¶é•¿åº¦

# 5. è¿”å›ç»“æœ
return title
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
# åœ¨ OutputHandler ä¸­ä½¿ç”¨
title_generator = TitleGenerator(llm_client=llm_client)

if "æœªå‘½å" in title:
    title = await title_generator.generate_title(
        content_md=processor_result.content_md,
        mode=ctx.mode,
        original_doc_title=source_doc.title
    )
```

---

## 7. ä»»åŠ¡å­˜å‚¨ (TaskStore)

**æ–‡ä»¶ä½ç½®**ï¼š`backend/core/task_store.py`

### 7.1 æ ¸å¿ƒèŒè´£

- ç®¡ç†ä»»åŠ¡çŠ¶æ€ï¼ˆå†…å­˜å®ç°ï¼‰
- æä¾›ä»»åŠ¡æŸ¥è¯¢
- æ”¯æŒå¹‚ç­‰æ§åˆ¶
- è®°å½•è¿›åº¦ä¿¡æ¯

### 7.2 æ•°æ®ç»“æ„

#### Task ç»“æ„

```python
{
    "status": "running" | "succeeded" | "failed",
    "created_at": float,           # åˆ›å»ºæ—¶é—´æˆ³
    "updated_at": float | None,    # æ›´æ–°æ—¶é—´æˆ³
    "context": Dict[str, Any],     # å¤„ç†ä¸Šä¸‹æ–‡
    "progress": {                  # è¿›åº¦ä¿¡æ¯
        "stage": str,
        "percent": int,
        "message": str
    },
    "result": Dict[str, Any] | None,  # æˆåŠŸç»“æœ
    "error": str | None                # é”™è¯¯ä¿¡æ¯
}
```

### 7.3 å…³é”®æ¥å£

```python
class TaskStore:
    async def create_task(
        self, 
        *, 
        context: Dict[str, Any],
        idempotency_key: str | None = None
    ) -> str:
        """åˆ›å»ºä»»åŠ¡ï¼Œè¿”å› task_id"""
    
    async def update_progress(
        self,
        task_id: str,
        *,
        stage: str,
        percent: int | None = None,
        message: str | None = None
    ) -> None:
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
    
    async def succeed(
        self, 
        task_id: str, 
        result: Dict[str, Any]
    ) -> None:
        """æ ‡è®°ä»»åŠ¡æˆåŠŸ"""
    
    async def fail(
        self, 
        task_id: str, 
        error: str
    ) -> None:
        """æ ‡è®°ä»»åŠ¡å¤±è´¥"""
    
    async def get(
        self, 
        task_id: str
    ) -> Optional[Dict[str, Any]]:
        """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
```

### 7.4 å¹‚ç­‰æ§åˆ¶

**å®ç°**ï¼š
```python
# å†…éƒ¨ç»´æŠ¤ idempotency_key â†’ task_id æ˜ å°„
self._idempotency: Dict[str, str] = {}

async def create_task(self, *, context, idempotency_key):
    if idempotency_key:
        existing = self._idempotency.get(idempotency_key)
        if existing and existing in self._tasks:
            return existing  # è¿”å›å·²å­˜åœ¨çš„ä»»åŠ¡
    
    # åˆ›å»ºæ–°ä»»åŠ¡
    task_id = uuid.uuid4().hex
    self._tasks[task_id] = {...}
    
    if idempotency_key:
        self._idempotency[idempotency_key] = task_id
    
    return task_id
```

**åº”ç”¨åœºæ™¯**ï¼š
- é£ä¹¦äº‹ä»¶å›è°ƒï¼ˆä½¿ç”¨ `event_id` å»é‡ï¼‰
- å¡ç‰‡æŒ‰é’®äº¤äº’ï¼ˆä½¿ç”¨ `request_id` å»é‡ï¼‰

### 7.5 æœªæ¥æ‰©å±•

**å½“å‰é™åˆ¶**ï¼š
- ä»…å†…å­˜å­˜å‚¨ï¼ˆé‡å¯ä¸¢å¤±ï¼‰
- ä¸æ”¯æŒåˆ†å¸ƒå¼
- æ— æŒä¹…åŒ–

**å‡çº§æ–¹å‘**ï¼š
- **Redis**ï¼šæ”¯æŒåˆ†å¸ƒå¼ã€æŒä¹…åŒ–
- **æ•°æ®åº“**ï¼šæ”¯æŒå†å²è®°å½•ã€ç»Ÿè®¡åˆ†æ

**Redis å®ç°ç¤ºä¾‹**ï¼š
```python
class RedisTaskStore(TaskStore):
    async def create_task(self, *, context, idempotency_key):
        task_id = uuid.uuid4().hex
        await redis.setex(
            f"task:{task_id}",
            3600,  # TTL: 1 hour
            json.dumps({
                "status": "running",
                "context": context,
                ...
            })
        )
        return task_id
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [æ¶æ„æ¦‚è§ˆ](architecture_overview.md)
- [é£ä¹¦å¼€æ”¾å¹³å°æ–‡æ¡£](https://open.feishu.cn/document/)
- [FastAPI æ–‡æ¡£](https://fastapi.tiangolo.com/)
- [Pydantic æ–‡æ¡£](https://docs.pydantic.dev/)

---

> ğŸ“ **ç»´æŠ¤è¯´æ˜**ï¼šæœ¬æ–‡æ¡£éšé¡¹ç›®æ›´æ–°ï¼Œè¯·ä¿æŒåŒæ­¥æ›´æ–°
